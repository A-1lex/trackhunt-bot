import aiohttp
import logging
from bs4 import BeautifulSoup
import urllib.parse

# –†–æ–±–æ—á—ñ —Å–∞–π—Ç–∏, —è–∫—ñ –º–∏ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–µ—Ä–µ–∑ Google
SEARCH_SITES = [
    "mp3xa.fm",
    "mp3uk.net"
]

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36"
}


async def search_music_links(query: str) -> list:
    """
    –®—É–∫–∞—î —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∑ mp3 –Ω–∞ mp3xa.fm —ñ mp3uk.net —á–µ—Ä–µ–∑ Google –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–∏–º –∑–∞–ø–∏—Ç–æ–º.
    """
    results = []

    for site in SEARCH_SITES:
        # ‚úÖ –ü–æ–∫—Ä–∞—â–µ–Ω–∏–π –∑–∞–ø–∏—Ç: —Ç–æ—á–Ω–∞ —Ñ—Ä–∞–∑–∞ + —Ñ—ñ–ª—å—Ç—Ä —Ç–∏–ø—É —Ñ–∞–π–ª—É
        search_query = f'"{query}" site:{site} filetype:mp3'
        encoded_query = urllib.parse.quote_plus(search_query)
        search_url = f"https://www.google.com/search?q={encoded_query}"

        try:
            async with aiohttp.ClientSession(headers=HEADERS) as session:
                async with session.get(search_url, timeout=10) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, "html.parser")
                        for a in soup.find_all("a"):
                            href = a.get("href", "")
                            if site in href and "/url?q=" in href:
                                clean_url = href.split("/url?q=")[1].split("&")[0]
                                if clean_url not in results:
                                    results.append(clean_url)
        except Exception as e:
            logging.warning(f"üîç –ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Ç—É –¥–æ Google –¥–ª—è {site}: {e}")

    logging.info(f"üîó –ó–Ω–∞–π–¥–µ–Ω–æ {len(results)} –ø–æ—Å–∏–ª–∞–Ω—å –¥–ª—è: {query}")
    return results

import aiohttp
import logging
from bs4 import BeautifulSoup
import urllib.parse

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36"
}


async def search_music_links(query: str) -> list:
    """
    –ü–æ—à—É–∫ —Ç—Ä–µ–∫—ñ–≤ –Ω–∞ mp3xa.fm.
    –®—É–∫–∞—î –≤—Å—ñ <a href="/...html"> –ø–æ—Å–∏–ª–∞–Ω–Ω—è, —è–∫—ñ –≤–µ–¥—É—Ç—å –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∑ —Ç—Ä–µ–∫–∞–º–∏.
    """
    results = []
    encoded_query = urllib.parse.quote_plus(query)
    search_url = f"https://mp3xa.fm/search/?q={encoded_query}"

    try:
        async with aiohttp.ClientSession(headers=HEADERS) as session:
            async with session.get(search_url, timeout=10) as response:
                if response.status == 200:
                    html = await response.text()
                    soup = BeautifulSoup(html, "html.parser")

                    # –®—É–∫–∞—î–º–æ –≤—Å—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∑ —Ç—Ä–µ–∫–∞–º–∏
                    for a in soup.find_all("a", href=True):
                        href = a["href"]
                        if href.startswith("/") and href.endswith(".html"):
                            full_url = f"https://mp3xa.fm{href}"
                            if full_url not in results:
                                results.append(full_url)

    except Exception as e:
        logging.warning(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É –Ω–∞ mp3xa.fm: {e}")

    logging.info(f"üîó –ó–Ω–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è '{query}'")
    return results

import aiohttp
import logging
from bs4 import BeautifulSoup
import urllib.parse

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36"
}


async def search_music_links(query: str) -> list:
    """
    –®—É–∫–∞—î –ø—ñ—Å–Ω—é –Ω–∞–ø—Ä—è–º—É –Ω–∞ mp3xa.fm —á–µ—Ä–µ–∑ —ó—Ö–Ω—ñ–π –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ–π –ø–æ—à—É–∫.
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ –ø–æ—Å–∏–ª–∞–Ω—å –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ —Ç—Ä–µ–∫—ñ–≤.
    """
    results = []
    search_query = urllib.parse.quote_plus(query)
    search_url = f"https://mp3xa.fm/search/?q={search_query}"

    try:
        async with aiohttp.ClientSession(headers=HEADERS) as session:
            async with session.get(search_url, timeout=10) as response:
                if response.status == 200:
                    html = await response.text()
                    soup = BeautifulSoup(html, "html.parser")

                    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –ø–µ—Ä—à—ñ <a href="/mp3/...">
                    for a in soup.find_all("a", href=True):
                        href = a["href"]
                        if href.startswith("/mp3/") and href.endswith(".html"):
                            full_url = f"https://mp3xa.fm{href}"
                            if full_url not in results:
                                results.append(full_url)

    except Exception as e:
        logging.warning(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø—Ä—è–º–æ–º—É –ø–æ—à—É–∫—É –Ω–∞ mp3xa.fm: {e}")

    logging.info(f"üîó –ó–Ω–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è '{query}'")
    return results

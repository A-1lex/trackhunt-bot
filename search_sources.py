import aiohttp
import logging
from bs4 import BeautifulSoup
import urllib.parse

# –°–∞–π—Ç–∏, —è–∫—ñ —Ä–µ–∞–ª—å–Ω–æ –≤–∏–¥–∞—é—Ç—å mp3
SEARCH_SITES = [
    "mp3xa.fm",
    "mp3uk.net"
]

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36"
}


async def search_music_links(query: str) -> list:
    """
    –í–∏–∫–æ–Ω—É—î Google-–ø–æ—à—É–∫ –ø–æ –∑–∞–∑–Ω–∞—á–µ–Ω–∏—Ö —Å–∞–π—Ç–∞—Ö.
    –ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ —Ç—Ä–µ–∫—ñ–≤ (–Ω–µ –æ–±–æ–≤'—è–∑–∫–æ–≤–æ mp3).
    """
    results = []

    for site in SEARCH_SITES:
        # üîÅ –ù–æ–≤–∞ –ª–æ–≥—ñ–∫–∞: —à–∏—Ä—à–∏–π –∑–∞–ø–∏—Ç –±–µ–∑ filetype
        search_query = f'"{query}" site:{site}'
        encoded_query = urllib.parse.quote_plus(search_query)
        search_url = f"https://www.google.com/search?q={encoded_query}"

        try:
            async with aiohttp.ClientSession(headers=HEADERS) as session:
                async with session.get(search_url, timeout=10) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, "html.parser")
                        for a in soup.find_all("a"):
                            href = a.get("href", "")
                            if site in href and "/url?q=" in href:
                                clean_url = href.split("/url?q=")[1].split("&")[0]
                                if clean_url not in results:
                                    results.append(clean_url)
        except Exception as e:
            logging.warning(f"üîç –ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Ç—É –¥–æ Google –¥–ª—è {site}: {e}")

    logging.info(f"üîó –ó–Ω–∞–π–¥–µ–Ω–æ {len(results)} –ø–æ—Å–∏–ª–∞–Ω—å –¥–ª—è: {query}")
    return results
